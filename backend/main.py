import cv2
import numpy as np
import pickle
import asyncio
import base64
import requests
import json
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import socketio
import os
import glob

# íŒ¨í‚¹ ì•Œê³ ë¦¬ì¦˜ import ì¶”ê°€
from wire_packing import solve
# from cosmos_db import save_measurement_to_cosmos  # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ

# Pydantic ëª¨ë¸ ì •ì˜
class PackingRequest(BaseModel):
    items: List[List[int]]

class ItemDimension(BaseModel):
    width: float
    length: float  
    height: float

# OpenCV ì„¤ì • ìµœì í™” (MSMF ì—ëŸ¬ ë°©ì§€)
os.environ['OPENCV_VIDEOIO_MSMF_ENABLE_HW_TRANSFORMS'] = '0'
os.environ['OPENCV_VIDEOIO_PRIORITY_MSMF'] = '0'  # MSMF ìš°ì„ ìˆœìœ„ ë‚®ì¶¤
cv2.setLogLevel(3)  # ê²½ê³  ë©”ì‹œì§€ ìµœì†Œí™”

# ë°•ìŠ¤ ì¶”ì²œ API ì„¤ì •
BOX_RECOMMENDATION_URL = "http://localhost:8001/recommend"  # ë°•ìŠ¤ ì¶”ì²œ API URL

# ìš°ì²´êµ­ íƒë°° ë°•ìŠ¤ ê·œê²© ì •ë³´
BOX_SPECS = {
    "1í˜¸": {"dimensions": "220 Ã— 190 Ã— 90mm", "maxW": 220, "maxL": 190, "maxH": 90, "price": "700ì›"},
    "2í˜¸": {"dimensions": "270 Ã— 180 Ã— 150mm", "maxW": 270, "maxL": 180, "maxH": 150, "price": "800ì›"},
    "2-1í˜¸": {"dimensions": "350 Ã— 250 Ã— 100mm", "maxW": 350, "maxL": 250, "maxH": 100, "price": "900ì›"},
    "3í˜¸": {"dimensions": "340 Ã— 250 Ã— 210mm", "maxW": 340, "maxL": 250, "maxH": 210, "price": "1,100ì›"},
    "4í˜¸": {"dimensions": "410 Ã— 310 Ã— 280mm", "maxW": 410, "maxL": 310, "maxH": 280, "price": "1,300ì›"},
    "5í˜¸": {"dimensions": "520 Ã— 380 Ã— 340mm", "maxW": 520, "maxL": 380, "maxH": 340, "price": "1,500ì›"},
    "6í˜¸": {"dimensions": "520 Ã— 480 Ã— 400mm", "maxW": 520, "maxL": 480, "maxH": 400, "price": "1,700ì›"},
    "7í˜¸": {"dimensions": "620 Ã— 480 Ã— 400mm", "maxW": 620, "maxL": 480, "maxH": 400, "price": "1,900ì›"}
}

# ë¡œì»¬ ë°•ìŠ¤ ì¶”ì²œ í•¨ìˆ˜ (API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ë°±ì—…ìš©)
def recommend_box_locally(width, length, height):
    """
    ë¡œì»¬ì—ì„œ ë°•ìŠ¤ ì¶”ì²œì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    """
    safety_margin = 1.05  # 5% ì—¬ìœ  ê³µê°„
    
    # ë°•ìŠ¤ ìˆœì„œëŒ€ë¡œ í™•ì¸
    for box_name, specs in BOX_SPECS.items():
        fits_width = (width * safety_margin) <= specs["maxW"]
        fits_length = (length * safety_margin) <= specs["maxL"] 
        fits_height = (height * safety_margin) <= specs["maxH"]
        
        if fits_width and fits_length and fits_height:
            return {
                "box_name": box_name,
                "dimensions": specs["dimensions"],
                "specs": specs
            }
    
    # ëª¨ë“  ë°•ìŠ¤ì— ì•ˆ ë§ìœ¼ë©´ ê°€ì¥ í° ë°•ìŠ¤ ì¶”ì²œ
    return {
        "box_name": "íŠ¹ìˆ˜ í¬ì¥",
        "dimensions": "í‘œì¤€ ë°•ìŠ¤ë³´ë‹¤ í° ë¬¼ì²´ì…ë‹ˆë‹¤",
        "specs": {"maxW": 999, "maxL": 999, "maxH": 999}
    }

async def call_box_recommendation_api(width, length, height):
    """
    ë°•ìŠ¤ ì¶”ì²œ APIë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ (app.py ì„œë¹„ìŠ¤)
    """
    try:
        payload = {
            "width": float(width),
            "length": float(length), 
            "height": float(height)
        }
        
        print(f"ğŸ“ ë°•ìŠ¤ ì¶”ì²œ API í˜¸ì¶œ: {payload}")
        
        # API í˜¸ì¶œ (timeout ì„¤ì •)
        response = requests.post(
            BOX_RECOMMENDATION_URL,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… API ì‘ë‹µ: {result}")
            
            if result.get("success"):
                recommended_box_name = result["data"]["recommended_box"]
                
                # ë°•ìŠ¤ ìŠ¤í™ ì •ë³´ ì¶”ê°€
                if recommended_box_name in BOX_SPECS:
                    box_info = BOX_SPECS[recommended_box_name].copy()
                    box_info["box_name"] = recommended_box_name
                    
                    return {
                        "success": True,
                        "box_name": recommended_box_name,
                        "dimensions": box_info["dimensions"],
                        "price": box_info["price"],
                        "specs": {
                            "maxW": box_info["maxW"],
                            "maxL": box_info["maxL"], 
                            "maxH": box_info["maxH"]
                        },
                        "api_result": result
                    }
                else:
                    print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë°•ìŠ¤ ì´ë¦„: {recommended_box_name}")
                    return {
                        "success": False,
                        "error": f"ì•Œ ìˆ˜ ì—†ëŠ” ë°•ìŠ¤: {recommended_box_name}"
                    }
            else:
                print(f"âŒ API ì‘ë‹µ ì˜¤ë¥˜: {result}")
                return {
                    "success": False,
                    "error": result.get('error', 'API ì‘ë‹µ ì˜¤ë¥˜')
                }
        else:
            print(f"âŒ API HTTP ì˜¤ë¥˜: {response.status_code}")
            return {
                "success": False,
                "error": f"HTTP {response.status_code} ì˜¤ë¥˜"
            }
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ API ì—°ê²° ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": f"ì—°ê²° ì˜¤ë¥˜: {str(e)}"
        }
    except Exception as e:
        print(f"âŒ API í˜¸ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return {
            "success": False,
            "error": f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
        }

# ----------------- ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•¨ìˆ˜ë“¤ -----------------
def calibrate_camera():
    """ì²´ì»¤ë³´ë“œë¥¼ ì´ìš©í•œ ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜"""
    # ì²´ì»¤ë³´ë“œì˜ ì°¨ì› ì •ì˜
    CHECKERBOARD = (7,10)  # ì²´ì»¤ë³´ë“œ í–‰ê³¼ ì—´ë‹¹ ë‚´ë¶€ ì½”ë„ˆ ìˆ˜
    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)
    
    # ê° ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€ì— ëŒ€í•œ 3D ì  ë²¡í„°ë¥¼ ì €ì¥í•  ë²¡í„° ìƒì„±
    objpoints = []
    # ê° ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€ì— ëŒ€í•œ 2D ì  ë²¡í„°ë¥¼ ì €ì¥í•  ë²¡í„° ìƒì„±
    imgpoints = [] 
    
    # 3D ì ì˜ ì„¸ê³„ ì¢Œí‘œ ì •ì˜
    objp = np.zeros((1, CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)
    objp[0,:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)
    
    # ì£¼ì–´ì§„ ë””ë ‰í„°ë¦¬ì— ì €ì¥ëœ ê°œë³„ ì´ë¯¸ì§€ì˜ ê²½ë¡œ ì¶”ì¶œ
    images = glob.glob('./checkerboards/*.jpg')
    
    if not images:
        print("âŒ ./checkerboards/ ë””ë ‰í„°ë¦¬ì— ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ“¸ ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€ë¥¼ ì´¬ì˜í•˜ì—¬ ./checkerboards/ í´ë”ì— ì €ì¥í•´ì£¼ì„¸ìš”.")
        return None
    
    print(f"ğŸ“¸ {len(images)}ê°œì˜ ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    
    for fname in images:
        img = cv2.imread(fname)
        if img is None:
            continue
            
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # ì²´ì»¤ë³´ë“œ ì½”ë„ˆ ì°¾ê¸°
        ret, corners = cv2.findChessboardCorners(gray,
                                               CHECKERBOARD,
                                               cv2.CALIB_CB_ADAPTIVE_THRESH +
                                               cv2.CALIB_CB_FAST_CHECK +
                                               cv2.CALIB_CB_NORMALIZE_IMAGE)
        
        if ret == True:
            objpoints.append(objp)
            corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)
            imgpoints.append(corners2)
            
            print(f"âœ… ì²´ì»¤ë³´ë“œ ë°œê²¬: {os.path.basename(fname)}")
        else:
            print(f"âŒ ì²´ì»¤ë³´ë“œ ë¯¸ë°œê²¬: {os.path.basename(fname)}")
    
    if len(objpoints) < 10:
        print(f"âš ï¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 10ê°œì˜ ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {len(objpoints)}ê°œ)")
        return None
    
    print(f"ğŸ”§ {len(objpoints)}ê°œ ì´ë¯¸ì§€ë¡œ ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰
    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints,
                                                      gray.shape[::-1], None, None)
    
    if ret:
        # ê²°ê³¼ ì¶œë ¥
        print("âœ… ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ!")
        print("ğŸ“ Camera matrix:")
        print(mtx)
        print("\nğŸ” Distortion coefficients:")
        print(dist)
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        calibration_data = {
            'camera_matrix': mtx,
            'dist_coeffs': dist,
            'rvecs': rvecs,
            'tvecs': tvecs
        }
        
        with open('camera_calibration.pkl', 'wb') as f:
            pickle.dump(calibration_data, f)
        
        print("ğŸ’¾ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ 'camera_calibration.pkl'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return calibration_data
    else:
        print("âŒ ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨")
        return None

def live_video_correction_demo(calibration_data):
    """ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ì™œê³¡ ë³´ì • ë°ëª¨"""
    mtx = calibration_data['camera_matrix']
    dist = calibration_data['dist_coeffs']
    
    cap = initialize_camera()
    if cap is None:
        print("âŒ ë°ëª¨ìš© ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("ğŸ¥ ì‹¤ì‹œê°„ ì™œê³¡ ë³´ì • ë°ëª¨ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. 'q'ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.")
    
    consecutive_failures = 0
    max_failures = 5
    
    while True:
        ret, frame = cap.read()
        if not ret or frame is None:
            consecutive_failures += 1
            if consecutive_failures >= max_failures:
                print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨ê°€ ì§€ì†ë©ë‹ˆë‹¤. ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            continue
        else:
            consecutive_failures = 0
        
        # í”„ë ˆì„ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
        h, w = frame.shape[:2]
        
        # ìµœì ì˜ ì¹´ë©”ë¼ í–‰ë ¬ êµ¬í•˜ê¸°
        newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))
        
        # ì™œê³¡ ë³´ì •
        dst = cv2.undistort(frame, mtx, dist, None, newcameramtx)
        
        # ROIë¡œ ì´ë¯¸ì§€ ìë¥´ê¸°
        x, y, w_roi, h_roi = roi
        if all(v > 0 for v in [x, y, w_roi, h_roi]):
            dst = dst[y:y+h_roi, x:x+w_roi]
        
        # ì›ë³¸ê³¼ ë³´ì •ëœ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ í‘œì‹œ
        original = cv2.resize(frame, (640, 480))
        corrected = cv2.resize(dst, (640, 480))
        combined = np.hstack((original, corrected))
        
        # í…ìŠ¤íŠ¸ ì¶”ê°€
        cv2.putText(combined, "Original", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(combined, "Corrected", (650, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # ê²°ê³¼ í‘œì‹œ
        cv2.imshow('Camera Calibration Demo - Original | Corrected', combined)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()

# ----------------- ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìƒì„± -----------------
def load_or_create_calibration():
    """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±"""
    try:
        with open('camera_calibration.pkl', 'rb') as f:
            calibration_data = pickle.load(f)
        print("âœ… ê¸°ì¡´ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ì„±ê³µ")
        return calibration_data['camera_matrix'], calibration_data['dist_coeffs']
    except Exception as e:
        print(f"âš ï¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ğŸ”§ ìƒˆë¡œìš´ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ì²´ì»¤ë³´ë“œ ë””ë ‰í„°ë¦¬ í™•ì¸
        if not os.path.exists('./checkerboards'):
            os.makedirs('./checkerboards')
            print("ğŸ“ ./checkerboards/ ë””ë ‰í„°ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            print("ğŸ“¸ ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€ë¥¼ ì´¬ì˜í•˜ì—¬ ì´ í´ë”ì— ì €ì¥í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None, None
        
        calibration_data = calibrate_camera()
        if calibration_data:
            return calibration_data['camera_matrix'], calibration_data['dist_coeffs']
        else:
            print("âŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨. ê¸°ë³¸ê°’ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            return None, None

# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ
camera_matrix, dist_coeffs = load_or_create_calibration()

# ArUco ì„¤ì •
aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_250)
aruco_params = cv2.aruco.DetectorParameters()
detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params)
marker_size = 30  # 30mm

# ë§ˆì»¤ 3D ì¢Œí‘œ (ë¯¸ë¦¬ ê³„ì‚°)
marker_3d_edges = np.array([
    [0, 0, 0],
    [0, marker_size, 0],
    [marker_size, marker_size, 0],
    [marker_size, 0, 0]
], dtype='float32').reshape((4, 1, 3))

# ----------------- FastAPI ë° Socket.IO ì„¤ì • -----------------
sio = socketio.AsyncServer(async_mode='asgi', cors_allowed_origins='*')
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app_asgi = socketio.ASGIApp(sio, app)

# ë§ˆì§€ë§‰ ì¸¡ì •ê°’ì„ ì €ì¥í•  ë³€ìˆ˜ (ì „ì—­)
last_box = None
last_dim_text = ""
last_recommendation = None  # ì¶”ê°€: ë§ˆì§€ë§‰ ë°•ìŠ¤ ì¶”ì²œ ê²°ê³¼
# ìµœì‹  í”„ë ˆì„ ê³µìœ ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ì™€ Lock
latest_frame = None
frame_lock = asyncio.Lock()
# ì™œê³¡ ë³´ì • ë§µ (ì „ì—­ìœ¼ë¡œ ì„ ì–¸)
map1, map2 = None, None

# ----------------- íŒ¨í‚¹ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ -----------------
@app.post("/pack/boxes")
async def get_box_data(request: Optional[PackingRequest] = None):
    """3D íŒ¨í‚¹ ì•Œê³ ë¦¬ì¦˜ì„ ì´ìš©í•œ ë°•ìŠ¤ ë°ì´í„° ìƒì„±"""
    try:
        print("ğŸ“¦ íŒ¨í‚¹ API í˜¸ì¶œë¨")
        
        # ìš”ì²­ ë°ì´í„°ì—ì„œ ë¬¼ì²´ ì •ë³´ ì¶”ì¶œ
        if request and request.items:
            items = [tuple(item) for item in request.items]
            print(f"ğŸ“¦ í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë°›ì€ ë¬¼ì²´ ë°ì´í„°: {items}")
        else:
            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°
            items = [(50, 30, 20), (40, 40, 15), (60, 25, 10)]
            print("ğŸ“¦ ìš”ì²­ ë°ì´í„° ì—†ìŒ - ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©")

        # ì…ë ¥ ë°ì´í„° ê²€ì¦
        if not items:
            raise ValueError("ë¬¼ì²´ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        for i, item in enumerate(items):
            if len(item) != 3:
                raise ValueError(f"ë¬¼ì²´ {i}ì˜ ì°¨ì› ë°ì´í„°ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤: {item}")
            if any(x <= 0 for x in item):
                raise ValueError(f"ë¬¼ì²´ {i}ì˜ í¬ê¸°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {item}")

        print(f"ğŸ”§ íŒ¨í‚¹ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ì‹œì‘...")
        
        # íŒ¨í‚¹ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
        box, placements = solve(items)
        print(f"âœ… íŒ¨í‚¹ ì•Œê³ ë¦¬ì¦˜ ì™„ë£Œ: ì»¨í…Œì´ë„ˆ {box}")

        # ê²°ê³¼ JSON êµ¬ì„±
        results = []
        for idx, dim, pos in placements:
            item_data = {
                "id": idx,
                "size": {"w": dim[0], "d": dim[1], "h": dim[2]},
                "pos": {"x": pos[0], "y": pos[1], "z": pos[2]},
                "original_item": list(items[idx]) if idx < len(items) else [3, 3, 3]
            }
            results.append(item_data)
            print(f"  ì•„ì´í…œ {idx}: {dim} at {pos}")

        # ë°•ìŠ¤ íƒ€ì… ê²°ì • (í¬ê¸°ì— ë”°ë¼)
        volume = box[0] * box[1] * box[2]
        if volume <= 50000:  # 50x50x20 ì •ë„
            box_type = "ì†Œí˜•"
        elif volume <= 500000:  # 100x100x50 ì •ë„
            box_type = "ì¤‘í˜•"
        else:
            box_type = "ëŒ€í˜•"

        # íŒ¨í‚¹ íš¨ìœ¨ì„± ê³„ì‚°
        total_item_volume = sum(item[0] * item[1] * item[2] for item in items)
        efficiency = round((total_item_volume / volume) * 100, 1) if volume > 0 else 0

        print(f"ğŸ“Š íŒ¨í‚¹ ê²°ê³¼ ìš”ì•½:")
        print(f"  - ì»¨í…Œì´ë„ˆ í¬ê¸°: {box}")
        print(f"  - ì´ ë¶€í”¼: {volume}")
        print(f"  - íš¨ìœ¨ì„±: {efficiency}%")
        print(f"  - ë°•ìŠ¤ íƒ€ì…: {box_type}")
        
        # ğŸ”¥ ë°•ìŠ¤ ì¶”ì²œ API í˜¸ì¶œ (app.py ì„œë¹„ìŠ¤)
        print("ğŸ“¦ Azure OpenAI ê¸°ë°˜ ë°•ìŠ¤ ì¶”ì²œì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        box_recommendation = await call_box_recommendation_api(box[0], box[1], box[2])
        
        container_data = {
            "container_size": {"w": box[0], "d": box[1], "h": box[2]},
            "items": results,
            "volume": volume,
            "box_type": box_type,
            "efficiency": efficiency,
            "total_items": len(items),
            "input_items": [list(item) for item in items],
            "recommended_box": box_recommendation  # ğŸ”¥ ë°•ìŠ¤ ì¶”ì²œ ê²°ê³¼ ì¶”ê°€
        }
        
        if box_recommendation and box_recommendation.get("success"):
            print(f"âœ… ë°•ìŠ¤ ì¶”ì²œ ì™„ë£Œ: {box_recommendation['box_name']} ({box_recommendation['dimensions']})")
        else:
            print(f"âš ï¸ ë°•ìŠ¤ ì¶”ì²œ ì‹¤íŒ¨: {box_recommendation.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜') if box_recommendation else 'API ì‘ë‹µ ì—†ìŒ'}")
        
        # Cosmos DBì— ì €ì¥ (ì˜µì…˜)
        try:
            # save_measurement_to_cosmos(
            #     user_id="yuni",
            #     result={
            #         "width": box[0],
            #         "length": box[1], 
            #         "height": box[2],
            #         "box_type": box_type,
            #         "volume": volume,
            #         "items_count": len(items),
            #         "efficiency": efficiency,
            #         "input_items": [list(item) for item in items],
            #         "recommended_box": box_recommendation
            #     }
            # )
            print("ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ (ë¹„í™œì„±í™”ë¨)")
        except Exception as e:
            print(f"âš ï¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        
        return container_data
    
    except Exception as e:
        print(f"âŒ íŒ¨í‚¹ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
        return {
            "error": "íŒ¨í‚¹ ë°ì´í„° ìƒì„± ì‹¤íŒ¨",
            "message": str(e),
            "container_size": {"w": 100, "d": 100, "h": 50},
            "items": [],
            "volume": 500000,
            "box_type": "ì˜¤ë¥˜",
            "efficiency": 0,
            "total_items": 0,
            "input_items": [],
            "recommended_box": {
                "success": False,
                "error": "íŒ¨í‚¹ ê³„ì‚° ì‹¤íŒ¨ë¡œ ì¸í•œ ë°•ìŠ¤ ì¶”ì²œ ë¶ˆê°€"
            }
        }

# ----------------- ì˜ìƒ ì²˜ë¦¬ ë° ì›¹ì†Œì¼“ í†µì‹  -----------------
def initialize_camera():
    """ì¹´ë©”ë¼ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜"""
    print("ğŸ“· ì¹´ë©”ë¼ ì´ˆê¸°í™”ë¥¼ ì‹œë„í•©ë‹ˆë‹¤...")
    
    # ë°±ì—”ë“œ ìš°ì„ ìˆœìœ„: DirectShow -> Auto -> MSMF
    backends = [
        (cv2.CAP_DSHOW, "DirectShow"),
        (cv2.CAP_ANY, "Auto"),
        (cv2.CAP_MSMF, "MSMF")
    ]
    
    for backend, name in backends:
        print(f"ğŸ”„ {name} ë°±ì—”ë“œë¡œ ì¹´ë©”ë¼ ì—°ê²° ì‹œë„...")
        cap = cv2.VideoCapture(0, backend)
        
        if cap.isOpened():
            # ì¹´ë©”ë¼ ì„¤ì • ìµœì í™”
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv2.CAP_PROP_FPS, 30)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ í¬ê¸° ìµœì†Œí™”
            
            # í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ì½ê¸°
            ret, test_frame = cap.read()
            if ret and test_frame is not None:
                print(f"âœ… {name} ë°±ì—”ë“œë¡œ ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ!")
                print(f"ğŸ“ í•´ìƒë„: {int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))}x{int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))}")
                return cap
            else:
                print(f"âŒ {name} ë°±ì—”ë“œ: í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                cap.release()
        else:
            print(f"âŒ {name} ë°±ì—”ë“œ: ì¹´ë©”ë¼ ì—´ê¸° ì‹¤íŒ¨")
    
    print("âŒ ëª¨ë“  ë°±ì—”ë“œì—ì„œ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨")
    return None

async def video_stream_task():
    global last_box, last_dim_text, latest_frame, map1, map2, last_recommendation
    cap = initialize_camera()
    if cap is None:
        print("âŒ ì¹´ë©”ë¼ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì™œê³¡ ë³´ì • ë§µì„ í•œ ë²ˆë§Œ ìƒì„± (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
    if camera_matrix is not None and dist_coeffs is not None:
        h, w = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        # alpha=0 ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì™œê³¡ ë³´ì • íš¨ê³¼ê°€ ì˜ ë³´ì´ë„ë¡ í•¨ (ì£¼ë³€ë¶€ê°€ ì˜ë¦´ ìˆ˜ ìˆìŒ)
        new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, (w, h), 0, (w,h))
        map1, map2 = cv2.initUndistortRectifyMap(camera_matrix, dist_coeffs, None, new_camera_matrix, (w, h), 5) # 5 = CV_32FC1
        print("âœ… ì™œê³¡ ë³´ì • ë§µ(map1, map2) ìƒì„± ì™„ë£Œ (alpha=0).")
    else:
        print("âš ï¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ ì—†ì–´ ì™œê³¡ ë³´ì •ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨ ì¹´ìš´í„°
    consecutive_failures = 0
    max_failures = 10

    while True:
        ret, frame = cap.read()
        if not ret or frame is None:
            consecutive_failures += 1
            print(f"âš ï¸ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨ ({consecutive_failures}/{max_failures})")
            
            if consecutive_failures >= max_failures:
                print("ğŸ”„ ì¹´ë©”ë¼ ì¬ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                cap.release()
                await asyncio.sleep(1)
                cap = initialize_camera()
                if cap is None:
                    print("âŒ ì¹´ë©”ë¼ ì¬ì—°ê²° ì‹¤íŒ¨. 5ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.")
                    await asyncio.sleep(5)
                    continue
                consecutive_failures = 0
            else:
                await asyncio.sleep(0.1)
                continue
        else:
            consecutive_failures = 0  # ì„±ê³µ ì‹œ ì¹´ìš´í„° ë¦¬ì…‹

        # ìµœì‹  í”„ë ˆì„ì„ thread-safeí•˜ê²Œ ì €ì¥
        async with frame_lock:
            latest_frame = frame.copy()

        # ì™œê³¡ ë³´ì • (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ)
        if map1 is not None and map2 is not None:
            frame_undistorted = cv2.remap(frame, map1, map2, cv2.INTER_LINEAR)
        else:
            frame_undistorted = frame
        
        # ì‹¤ì‹œê°„ ë§ˆì»¤ ê²€ì¶œ (ì‹œê°ì  í”¼ë“œë°±ìš©)
        corners, ids, rejected = detector.detectMarkers(frame_undistorted)
        
        # ğŸ”¥ ë§ˆì»¤ ì¸ì‹ ìƒíƒœ í™•ì¸ (í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬í•  ì •ë³´)
        marker_detected = ids is not None and len(ids) > 0
        marker_count = len(ids) if ids is not None else 0

        # í™”ë©´ì— ê·¸ë¦¬ê¸°
        if marker_detected and camera_matrix is not None:
            cv2.aruco.drawDetectedMarkers(frame_undistorted, corners, ids)
            for corner in corners:
                ret_pnp, rvec, tvec = cv2.solvePnP(marker_3d_edges, corner, camera_matrix, dist_coeffs)
                if ret_pnp:
                    cv2.drawFrameAxes(frame_undistorted, camera_matrix, dist_coeffs, rvec, tvec, marker_size/2)
        elif marker_detected:
            cv2.aruco.drawDetectedMarkers(frame_undistorted, corners, ids)
        
        # ì¸¡ì • ê²°ê³¼ í‘œì‹œ
        if last_box is not None:
            cv2.drawContours(frame_undistorted, [last_box], 0, (0, 255, 0), 2)
            cv2.putText(frame_undistorted, last_dim_text, (int(last_box[1][0]), int(last_box[1][1] - 10)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 0), 2)
        
        # ë°•ìŠ¤ ì¶”ì²œ ê²°ê³¼ í‘œì‹œ
        if last_recommendation is not None:
            recommendation_text = f"ì¶”ì²œ: {last_recommendation['box_name']}"
            cv2.putText(frame_undistorted, recommendation_text, (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)

        # í”„ë ˆì„ì„ JPEGë¡œ ì¸ì½”ë”© í›„ Base64ë¡œ ë³€í™˜
        _, buffer = cv2.imencode('.jpg', frame_undistorted)
        frame_encoded = base64.b64encode(buffer).decode('utf-8')
        
        # ğŸ”¥ í´ë¼ì´ì–¸íŠ¸ë¡œ í”„ë ˆì„ê³¼ ë§ˆì»¤ ì¸ì‹ ìƒíƒœ í•¨ê»˜ ì „ì†¡
        await sio.emit('video_frame', {
            'image': frame_encoded,
            'marker_detected': marker_detected,  # ë§ˆì»¤ ì¸ì‹ ìƒíƒœ
            'marker_count': marker_count         # ë§ˆì»¤ ê°œìˆ˜
        })
        await asyncio.sleep(0.03) # í”„ë ˆì„ ì†ë„ ì¡°ì ˆ

# --- 3D ì¸¡ì • ë¡œì§ (í–¥ìƒëœ ë²„ì „) ---
@sio.on('measure')
async def measure_object(sid):
    global last_box, last_dim_text, latest_frame, map1, map2, last_recommendation
    
    print("ğŸ“ ì¸¡ì • ìš”ì²­ ìˆ˜ì‹ ...")
    
    # ê³µìœ ëœ ìµœì‹  í”„ë ˆì„ì„ ê°€ì ¸ì˜´
    async with frame_lock:
        if latest_frame is None:
            print("âŒ ì¸¡ì •ì— ì‚¬ìš©í•  í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
            await sio.emit('measurement_result', {'dimensions': 'ì¹´ë©”ë¼ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})
            return
        frame_for_measurement = latest_frame.copy()

    # ì™œê³¡ ë³´ì • (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ)
    if map1 is not None and map2 is not None:
        frame_undistorted = cv2.remap(frame_for_measurement, map1, map2, cv2.INTER_LINEAR)
    elif camera_matrix is not None and dist_coeffs is not None:
        print("âš ï¸ ì™œê³¡ ë³´ì • ë§µì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë³´ì •ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        frame_undistorted = cv2.undistort(frame_for_measurement, camera_matrix, dist_coeffs)
    else:
        print("âš ï¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ ì—†ì–´ ì™œê³¡ ë³´ì •ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        frame_undistorted = frame_for_measurement

    corners, ids, rejected = detector.detectMarkers(frame_undistorted)
    
    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 3D ì¸¡ì • ë¶ˆê°€
    if camera_matrix is None or dist_coeffs is None:
        print("âš ï¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ ì—†ì–´ 2D ì¸¡ì •ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        if ids is not None and len(ids) > 0:
            await perform_2d_measurement(frame_undistorted, corners, ids)
        else:
            await sio.emit('measurement_result', {'dimensions': 'ë§ˆì»¤ë¥¼ ë¨¼ì € ì¸ì‹ì‹œì¼œì£¼ì„¸ìš”.'})
        return
    
    if ids is not None and len(ids) >= 3:
        print(f"âœ… {len(ids)}ê°œì˜ ë§ˆì»¤ ë°œê²¬, 3D ì¸¡ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # --- 1. ë§ˆì»¤ 3D ìœ„ì¹˜(tvec) êµ¬í•˜ê¸° ---
        marker_tvecs = []
        for corner in corners:
            ret, rvec, tvec = cv2.solvePnP(marker_3d_edges, corner, camera_matrix, dist_coeffs)
            if ret:
                marker_tvecs.append(tvec.reshape(-1))
        
        if len(marker_tvecs) < 3:
            print("âŒ ìœ íš¨í•œ ë§ˆì»¤ê°€ 3ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.")
            await sio.emit('measurement_result', {'dimensions': 'ìœ íš¨í•œ ë§ˆì»¤ 3ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.'})
            return
            
        # --- 2. í‰ë©´ ë°©ì •ì‹ êµ¬í•˜ê¸° (ë§ˆì»¤ 3ê°œ ì‚¬ìš©) ---
        p1, p2, p3 = marker_tvecs[0], marker_tvecs[1], marker_tvecs[2]
        v1 = p2 - p1
        v2 = p3 - p1
        normal = np.cross(v1, v2)
        a, b, c = normal
        d = -np.dot(normal, p1)
        print(f"ğŸ“ í‰ë©´ ë°©ì •ì‹ ê³„ìˆ˜: a={a:.3f}, b={b:.3f}, c={c:.3f}, d={d:.3f}")
        
        # --- 3. ë¬¼ì²´ ìœ¤ê³½ì„  ì°¾ê¸° ---
        gray = cv2.cvtColor(frame_undistorted, cv2.COLOR_BGR2GRAY)
        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if contours:
            valid_contours = [cnt for cnt in contours if 100 < cv2.contourArea(cnt) < 20000]
            if valid_contours:
                # ê°€ì¥ í° ìœ¤ê³½ì„ ì„ ë¬¼ì²´ë¡œ ì„ íƒ
                object_contour = max(valid_contours, key=cv2.contourArea)
                rect = cv2.minAreaRect(object_contour)
                box = cv2.boxPoints(rect)
                last_box = box.astype(np.int32)
                width_px, height_px = rect[1]
                
                # --- 4. ë¬¼ì²´ ì¤‘ì‹¬ í”½ì…€ êµ¬í•˜ê¸° ---
                M = cv2.moments(object_contour)
                if M["m00"] != 0:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    
                    # --- 5. í”½ì…€ â†’ 3D ë³€í™˜ (ë°”ë‹¥ í‰ë©´ê³¼ì˜ êµì ) ---
                    uv1 = np.array([cx, cy, 1.0])
                    invK = np.linalg.inv(camera_matrix)
                    ray = invK @ uv1
                    
                    # ê´‘ì„ ê³¼ í‰ë©´ì˜ êµì  ê³„ì‚°
                    denominator = a*ray[0] + b*ray[1] + c*ray[2]
                    if abs(denominator) > 1e-6:  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                        t = -(a*0 + b*0 + c*0 + d) / denominator
                        P_ground = t * ray  # ë°”ë‹¥ í‰ë©´ ìœ„ì˜ 3D ì¢Œí‘œ
                        
                        # --- 6. ë¬¼ì²´ ìœ—ë©´ì˜ 3D ì¢Œí‘œ ì¶”ì • ---
                        # ìœ¤ê³½ì„ ì—ì„œ ê°€ì¥ ë†’ì€ yê°’(ì´ë¯¸ì§€ ì¢Œí‘œê³„ì—ì„œ ê°€ì¥ ì‘ì€ y) í”½ì…€ì„ ì°¾ìŒ
                        top_idx = np.argmin(object_contour[:,0,1])
                        top_px = object_contour[top_idx,0]
                        uv1_top = np.array([top_px[0], top_px[1], 1.0])
                        ray_top = invK @ uv1_top
                        
                        t_top = -(a*0 + b*0 + c*0 + d) / (a*ray_top[0] + b*ray_top[1] + c*ray_top[2])
                        P_top_ground = t_top * ray_top
                        
                        # ë†’ì´ ê³„ì‚° (Zì¶• ì°¨ì´)
                        height_3d_mm = abs(P_top_ground[2] - P_ground[2])
                        print(f"ğŸ” 3D ë†’ì´ ê³„ì‚°: {height_3d_mm:.1f}mm")
                    else:
                        height_3d_mm = 0
                        print("âš ï¸ í‰ë©´ê³¼ ê´‘ì„ ì´ í‰í–‰í•˜ì—¬ ë†’ì´ ê³„ì‚° ë¶ˆê°€")
                else:
                    height_3d_mm = 0
                    print("âš ï¸ ë¬¼ì²´ ì¤‘ì‹¬ì  ê³„ì‚° ì‹¤íŒ¨")
                
                # --- 7. 2D í¬ê¸°ë¥¼ mmë¡œ ë³€í™˜ ---
                all_pixel_sizes = []
                for corner in corners:
                    marker_corners = corner.reshape((4, 2))
                    pixel_width = np.linalg.norm(marker_corners[1] - marker_corners[0])
                    pixel_height = np.linalg.norm(marker_corners[2] - marker_corners[1])
                    all_pixel_sizes.append((pixel_width + pixel_height) / 2.0)
                
                avg_pixel_size = np.mean(all_pixel_sizes)
                px_per_mm = avg_pixel_size / marker_size if avg_pixel_size > 0 else 1
                print(f"ğŸ“ í”½ì…€-mm ë³€í™˜ ë¹„ìœ¨: {px_per_mm:.2f} px/mm")
                
                width_mm = width_px / px_per_mm
                height_2d_mm = height_px / px_per_mm
                
                # --- 8. ê²°ê³¼ í‘œì‹œ (3D ë†’ì´ í¬í•¨) ---
                if height_3d_mm > 0:
                    last_dim_text = f"W: {max(width_mm, height_2d_mm):.1f}mm, L: {min(width_mm, height_2d_mm):.1f}mm, H: {height_3d_mm:.1f}mm"
                    final_width = max(width_mm, height_2d_mm)
                    final_length = min(width_mm, height_2d_mm)
                    final_height = height_3d_mm
                else:
                    last_dim_text = f"W: {max(width_mm, height_2d_mm):.1f}mm, L: {min(width_mm, height_2d_mm):.1f}mm"
                    final_width = max(width_mm, height_2d_mm)
                    final_length = min(width_mm, height_2d_mm)
                    final_height = min(width_mm, height_2d_mm) * 0.6  # ê¸°ë³¸ ë†’ì´ ì¶”ì •
                
                print(f"âœ… 3D ì¸¡ì • ì™„ë£Œ: {last_dim_text}")
                
                # í´ë¼ì´ì–¸íŠ¸ë¡œ ì¸¡ì • ê²°ê³¼ ì „ì†¡ (ë°•ìŠ¤ ì¶”ì²œ ì œê±°)
                await sio.emit('measurement_result', {
                    'dimensions': last_dim_text,
                    'measurements': {
                        'width': final_width,
                        'length': final_length, 
                        'height': final_height
                    }
                })
                
            else:
                print("âŒ ì ì ˆí•œ í¬ê¸°ì˜ ë¬¼ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                await sio.emit('measurement_result', {'dimensions': 'ì ì ˆí•œ í¬ê¸°ì˜ ë¬¼ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})
        else:
            print("âŒ ë¬¼ì²´ì˜ ìœ¤ê³½ì„ ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            await sio.emit('measurement_result', {'dimensions': 'ë¬¼ì²´ì˜ ìœ¤ê³½ì„ ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})
            
    elif ids is not None and len(ids) > 0:
        print(f"âš ï¸ ë§ˆì»¤ {len(ids)}ê°œ ë°œê²¬ (3ê°œ ë¯¸ë§Œ) - 2D ì¸¡ì •ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
        await perform_2d_measurement(frame_undistorted, corners, ids)
            
    else:
        print("âŒ ë§ˆì»¤ê°€ ì—†ì–´ ì¸¡ì • ë¶ˆê°€")
        await sio.emit('measurement_result', {'dimensions': 'ë§ˆì»¤ë¥¼ ë¨¼ì € ì¸ì‹ì‹œì¼œì£¼ì„¸ìš”.'})

async def perform_2d_measurement(frame_undistorted, corners, ids):
    """2D ì¸¡ì • ë¡œì§ì„ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬"""
    global last_box, last_dim_text, last_recommendation
    
    # 2D ì¸¡ì • ë¡œì§ (ê¸°ì¡´ ë°©ì‹)
    all_pixel_sizes = []
    for corner in corners:
        marker_corners = corner.reshape((4, 2))
        pixel_width = np.linalg.norm(marker_corners[1] - marker_corners[0])
        pixel_height = np.linalg.norm(marker_corners[2] - marker_corners[1])
        all_pixel_sizes.append((pixel_width + pixel_height) / 2.0)
    
    avg_pixel_size = np.mean(all_pixel_sizes)
    px_per_mm = avg_pixel_size / marker_size if avg_pixel_size > 0 else 0

    if px_per_mm > 0:
        print(f"ğŸ“ í”½ì…€-mm ë³€í™˜ ë¹„ìœ¨: {px_per_mm:.2f} px/mm")
        
        # ë§ˆì»¤ë“¤ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
        all_centers_x = [int(np.mean([c[0] for c in corner.reshape((4, 2))])) for corner in corners]
        all_centers_y = [int(np.mean([c[1] for c in corner.reshape((4, 2))])) for corner in corners]
        area_center_x, area_center_y = int(np.mean(all_centers_x)), int(np.mean(all_centers_y))

        # ë¬¼ì²´ ìœ¤ê³½ì„  ì°¾ê¸°
        gray = cv2.cvtColor(frame_undistorted, cv2.COLOR_BGR2GRAY)
        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if contours:
            valid_contours = [cnt for cnt in contours if 100 < cv2.contourArea(cnt) < 20000]
            if valid_contours:
                # ë§ˆì»¤ ì˜ì—­ ì¤‘ì‹¬ì— ê°€ì¥ ê°€ê¹Œìš´ ìœ¤ê³½ì„  ì„ íƒ
                object_contour = min(valid_contours, key=lambda cnt: np.sqrt(
                    ((cv2.moments(cnt)['m10']/cv2.moments(cnt)['m00'] if cv2.moments(cnt)['m00'] != 0 else 0) - area_center_x)**2 + 
                    ((cv2.moments(cnt)['m01']/cv2.moments(cnt)['m00'] if cv2.moments(cnt)['m00'] != 0 else 0) - area_center_y)**2
                ))
                
                # ìµœì†Œ ì™¸ì ‘ ì‚¬ê°í˜• ê³„ì‚°
                rect = cv2.minAreaRect(object_contour)
                box = cv2.boxPoints(rect)
                last_box = box.astype(np.int32)
                
                # mm ë‹¨ìœ„ë¡œ ë³€í™˜
                width_mm = rect[1][0] / px_per_mm
                height_mm = rect[1][1] / px_per_mm
                final_width = max(width_mm, height_mm)
                final_length = min(width_mm, height_mm)
                final_height = final_length * 0.6  # 2Dì—ì„œëŠ” ë†’ì´ ì¶”ì •
                
                last_dim_text = f"W: {final_width:.1f}mm, L: {final_length:.1f}mm"
                
                print(f"âœ… 2D ì¸¡ì • ì™„ë£Œ: {last_dim_text}")
                
                # í´ë¼ì´ì–¸íŠ¸ë¡œ ì¸¡ì • ê²°ê³¼ ì „ì†¡ (ë°•ìŠ¤ ì¶”ì²œ ì œê±°)
                await sio.emit('measurement_result', {
                    'dimensions': last_dim_text,
                    'measurements': {
                        'width': final_width,
                        'length': final_length,
                        'height': final_height
                    }
                })
            else:
                print("âŒ ì ì ˆí•œ í¬ê¸°ì˜ ë¬¼ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                await sio.emit('measurement_result', {'dimensions': 'ì ì ˆí•œ í¬ê¸°ì˜ ë¬¼ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})
        else:
            print("âŒ ë¬¼ì²´ì˜ ìœ¤ê³½ì„ ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            await sio.emit('measurement_result', {'dimensions': 'ë¬¼ì²´ì˜ ìœ¤ê³½ì„ ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})
    else:
        print("âŒ í”½ì…€-mm ë³€í™˜ ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        await sio.emit('measurement_result', {'dimensions': 'ë§ˆì»¤ í¬ê¸°ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})

@sio.on('clear')
async def clear_measurement(sid):
    global last_box, last_dim_text, last_recommendation
    last_box = None
    last_dim_text = ""
    last_recommendation = None
    print("ğŸ§¹ ì¸¡ì •ê°’ ì´ˆê¸°í™”")
    await sio.emit('measurement_result', {'dimensions': ''})

@sio.on('connect')
async def connect(sid, environ):
    print(f"ğŸ”Œ Socket.IO Client connected: {sid}")
    # í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ë©´ ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    sio.start_background_task(video_stream_task)

@sio.on('disconnect')
def disconnect(sid):
    print(f"ğŸ”Œ Socket.IO Client disconnected: {sid}")

# ğŸ¥ í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@app.get("/")
async def health_check():
    return {"status": "OK", "message": "Product Photo Analyzer Backend is running", "port": 8002}

@app.get("/health")
async def health():
    # ì‹¤ì œ ì¹´ë©”ë¼ ìƒíƒœ í™•ì¸
    camera_available = False
    try:
        test_cap = initialize_camera()
        if test_cap is not None:
            camera_available = True
            test_cap.release()
    except Exception as e:
        print(f"âš ï¸ ì¹´ë©”ë¼ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return {
        "status": "healthy",
        "port": 8002,
        "camera_available": camera_available,
        "calibration_loaded": camera_matrix is not None and dist_coeffs is not None,
        "marker_dict": "DICT_4X4_250",
        "marker_size_mm": marker_size,
        "box_recommendation_api": BOX_RECOMMENDATION_URL,
        "packing_api_available": True
    }

@app.post("/pack/test")
async def test_packing():
    """íŒ¨í‚¹ ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸"""
    print("ğŸ§ª íŒ¨í‚¹ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    test_items = [
        [50, 30, 20],   # ë¬¼ì²´ 1: 50x30x20mm
        [40, 40, 15],   # ë¬¼ì²´ 2: 40x40x15mm  
        [60, 25, 10],   # ë¬¼ì²´ 3: 60x25x10mm
        [35, 35, 25]    # ë¬¼ì²´ 4: 35x35x25mm
    ]
    
    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        request = PackingRequest(items=test_items)
        result = await get_box_data(request)
        
        return {
            "test_data": test_items,
            "packing_result": result,
            "message": "âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ",
            "success": True
        }
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return {
            "test_data": test_items,
            "error": str(e),
            "message": "âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨",
            "success": False
        }

@app.get("/pack/debug")
async def debug_packing():
    """ë””ë²„ê¹…ìš© ì •ë³´ ì œê³µ"""
    try:
        # wire_packing ëª¨ë“ˆ ì§ì ‘ í…ŒìŠ¤íŠ¸
        from wire_packing import test_packing
        
        print("ğŸ” wire_packing ëª¨ë“ˆ ì§ì ‘ í…ŒìŠ¤íŠ¸")
        box_size, placements = test_packing()
        
        if box_size and placements:
            return {
                "module_test": "success",
                "box_size": box_size,
                "placements": [
                    {
                        "item_idx": p[0],
                        "size": p[1], 
                        "position": p[2]
                    } for p in placements
                ],
                "message": "wire_packing ëª¨ë“ˆ ì •ìƒ ë™ì‘"
            }
        else:
            return {
                "module_test": "failed",
                "message": "wire_packing ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨"
            }
            
    except Exception as e:
        import traceback
        return {
            "module_test": "error",
            "error": str(e),
            "traceback": traceback.format_exc(),
            "message": f"wire_packing ëª¨ë“ˆ ì˜¤ë¥˜: {e}"
        }

@app.post("/pack/simple")
async def simple_pack(items: List[List[int]]):
    """ê°„ë‹¨í•œ íŒ¨í‚¹ í…ŒìŠ¤íŠ¸"""
    try:
        print(f"ğŸ¯ ê°„ë‹¨í•œ íŒ¨í‚¹ í…ŒìŠ¤íŠ¸: {items}")
        
        # ì§ì ‘ solve í•¨ìˆ˜ í˜¸ì¶œ
        from wire_packing import solve
        
        items_tuples = [tuple(item) for item in items]
        box, placements = solve(items_tuples)
        
        return {
            "input": items,
            "box": box,
            "placements": [
                {
                    "id": p[0],
                    "size": p[1],
                    "pos": p[2]
                } for p in placements
            ],
            "success": True
        }
        
    except Exception as e:
        print(f"âŒ ê°„ë‹¨í•œ íŒ¨í‚¹ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "input": items,
            "error": str(e),
            "success": False
        }

# ğŸ”§ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
@app.get("/calibration/status")
async def calibration_status():
    """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ í™•ì¸"""
    return {
        "calibration_loaded": camera_matrix is not None and dist_coeffs is not None,
        "calibration_file_exists": os.path.exists('camera_calibration.pkl'),
        "checkerboard_images_count": len(glob.glob('./checkerboards/*.jpg'))
    }

@app.post("/calibration/run")
async def run_calibration():
    """ìƒˆë¡œìš´ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤í–‰"""
    global camera_matrix, dist_coeffs, map1, map2
    
    try:
        calibration_data = calibrate_camera()
        if calibration_data:
            camera_matrix = calibration_data['camera_matrix']
            dist_coeffs = calibration_data['dist_coeffs']
            
            # ì™œê³¡ ë³´ì • ë§µ ì¬ìƒì„±
            cap = cv2.VideoCapture(0)
            if cap.isOpened():
                h, w = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, (w, h), 0, (w,h))
                map1, map2 = cv2.initUndistortRectifyMap(camera_matrix, dist_coeffs, None, new_camera_matrix, (w, h), 5)
                cap.release()
            
            return {"status": "success", "message": "ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."}
        else:
            return {"status": "error", "message": "ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."}
    except Exception as e:
        return {"status": "error", "message": f"ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

@app.get("/calibration/demo")
async def calibration_demo():
    """ì™œê³¡ ë³´ì • ë°ëª¨ ì‹¤í–‰ (ë³„ë„ ì°½ì—ì„œ)"""
    if camera_matrix is not None and dist_coeffs is not None:
        try:
            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë°ëª¨ ì‹¤í–‰ (ë¸”ë¡œí‚¹ ë°©ì§€)
            import threading
            calibration_data = {'camera_matrix': camera_matrix, 'dist_coeffs': dist_coeffs}
            demo_thread = threading.Thread(target=live_video_correction_demo, args=(calibration_data,))
            demo_thread.daemon = True
            demo_thread.start()
            return {"status": "success", "message": "ì™œê³¡ ë³´ì • ë°ëª¨ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆ ì°½ì„ í™•ì¸í•˜ì„¸ìš”."}
        except Exception as e:
            return {"status": "error", "message": f"ë°ëª¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"}
    else:
        return {"status": "error", "message": "ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”."}

if __name__ == '__main__':
    import uvicorn
    print("ğŸš€ í†µí•© ìƒí’ˆ í¬ì¥ ë¶„ì„ê¸° ë°±ì—”ë“œ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ğŸ“¡ Socket.IO ì„œë²„: ws://127.0.0.1:8002")
    print("ğŸŒ HTTP API: http://127.0.0.1:8002")
    print("â¤ï¸ í—¬ìŠ¤ì²´í¬: http://127.0.0.1:8002/health")
    print("ğŸ“¦ íŒ¨í‚¹ API: http://127.0.0.1:8002/pack/boxes")
    print("ğŸ”§ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ: http://127.0.0.1:8002/calibration/status")
    print("ğŸ“ ì¸¡ì • ëª¨ë“œ: 3D (ë§ˆì»¤ 3ê°œ ì´ìƒ) + 2D (ë§ˆì»¤ 1-2ê°œ) í•˜ì´ë¸Œë¦¬ë“œ")
    print(f"ğŸ¤– AI ë°•ìŠ¤ ì¶”ì²œ API: {BOX_RECOMMENDATION_URL}")
    
    print("\nğŸ”§ ì¹´ë©”ë¼ ì—ëŸ¬ ë°œìƒ ì‹œ í•´ê²° ë°©ë²•:")
    print("1. ë‹¤ë¥¸ ì¹´ë©”ë¼ ì•±(Skype, Teams ë“±) ì¢…ë£Œ")
    print("2. ì›¹ìº  ë“œë¼ì´ë²„ ì—…ë°ì´íŠ¸")
    print("3. USB í¬íŠ¸ ë³€ê²½")
    print("4. Windows ì¹´ë©”ë¼ ì•±ì—ì„œ ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸")
    
    if camera_matrix is None or dist_coeffs is None:
        print("\nâš ï¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        print("ğŸ“¸ ì²´ì»¤ë³´ë“œ ì´ë¯¸ì§€ë¥¼ ./checkerboards/ í´ë”ì— ë„£ê³ ")
        print("ğŸ”§ POST /calibration/run ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
    else:
        print("\nâœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ - 3D ì¸¡ì • ê°€ëŠ¥")
    
    print("\nğŸ¤– AI ë°•ìŠ¤ ì¶”ì²œ ì‹œìŠ¤í…œ:")
    print("âœ… Azure OpenAI ê¸°ë°˜ ì§€ëŠ¥í˜• ë°•ìŠ¤ ì¶”ì²œ")
    print("ğŸ”„ AI ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ê³„ì‚° ìë™ ë°±ì—…")
    print("ğŸ“¦ ì „ì²´ ë¬¼ì²´ ì¸¡ì • ì™„ë£Œ í›„ ìµœì í™”")
    
    print("\nğŸ¯ 3D íŒ¨í‚¹ ì‹œë®¬ë ˆì´ì…˜:")
    print("âœ… /pack/boxes ì—”ë“œí¬ì¸íŠ¸ë¡œ 3D íŒ¨í‚¹ ë°ì´í„° ì œê³µ")
    print("ğŸ”„ íŒ¨í‚¹ íš¨ìœ¨ì„± ë° ë°•ìŠ¤ íƒ€ì… ìë™ ê³„ì‚°")
    print("ğŸ¤– íŒ¨í‚¹ ì™„ë£Œ í›„ AIê°€ ìµœì  ë°•ìŠ¤ ì¶”ì²œ")
    
    print("\nğŸ”— ê´€ë ¨ ì„œë¹„ìŠ¤:")
    print("ğŸ“ main.py (í¬íŠ¸ 8002): ì¹´ë©”ë¼, ì¸¡ì •, íŒ¨í‚¹")
    print("ğŸ¤– app.py (í¬íŠ¸ 8001): AI ë°•ìŠ¤ ì¶”ì²œ")
    print("ğŸ’¡ ë‘ ì„œë¹„ìŠ¤ ëª¨ë‘ ì‹¤í–‰ë˜ì–´ì•¼ ì •ìƒ ì‘ë™")
    
    uvicorn.run(app_asgi, host="127.0.0.1", port=8002)